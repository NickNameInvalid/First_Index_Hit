{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1411cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e00fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_output_query_idx = []\n",
    "def create_1st_layer(layer_type):\n",
    "    \n",
    "    query_file_name = layer_type + \"_queries.txt\"\n",
    "    query_file = open(query_file_name, \"r\", encoding='utf-8')\n",
    "    \n",
    "    output_path = \"query output\"\n",
    "    query_output_file_name = output_path + \"/\" + layer_type + \"_queries_output.txt\"\n",
    "    query_output_file = open(query_output_file_name, \"r\", encoding='utf-8')\n",
    "    \n",
    "    if layer_type == \"complete_single\":\n",
    "        layer_type = \"single\"\n",
    "    \n",
    "    query_line = query_file.readline()\n",
    "    while query_line:\n",
    "        # generate index list for this query\n",
    "        query_output_line = query_output_file.readline()\n",
    "        \n",
    "        # if no document contain this term, just skip this query\n",
    "        if query_output_line == \"\\n\":\n",
    "            #no_output_query_idx.append(query_line)\n",
    "            #query_line = query_file.readline()\n",
    "            #query_output_file.readline()\n",
    "            index_layer_path = \"./First Layer Index\"\n",
    "            query_line = query_line.replace(\"\\n\", \"\")\n",
    "            colon_pos = query_line.index(\":\")\n",
    "            #index_list_file_name = query_line[:colon_pos] + \"_\" + query_line[colon_pos + 1:]\n",
    "            index_list_file_name = layer_type.upper() + \"_\" + query_line[colon_pos + 1:]\n",
    "            \n",
    "            layer_index_file = open(index_layer_path + \"/\" + layer_type + \"/\" + index_list_file_name, \"w\", encoding='utf-8')\n",
    "            layer_index_file.close()\n",
    "            query_line = query_file.readline()\n",
    "        \n",
    "        # there are some results for this query\n",
    "        else:\n",
    "            index_layer_path = \"./First Layer Index\"\n",
    "            query_line = query_line.replace(\"\\n\", \"\")\n",
    "            colon_pos = query_line.index(\":\")\n",
    "            #index_list_file_name = query_line[:colon_pos] + \"_\" + query_line[colon_pos + 1:]\n",
    "            index_list_file_name = layer_type.upper() + \"_\" + query_line[colon_pos + 1:]\n",
    "            if index_list_file_name == \"SINGLE_drowings\":\n",
    "                print(\"Found\")\n",
    "            \n",
    "            '''\n",
    "            colon_pos = query_line.index(\":\")\n",
    "            index_list_file_name = query_line[colon_pos + 1:]\n",
    "            '''\n",
    "            #index_list_file_path_name = index_layer_path + \"/\" + layer_type + \"/\" + index_list_file_name + \".txt\"\n",
    "            #print(index_list_file_path_name)\n",
    "            #layer_index_file = open(index_layer_path + \"/\" + layer_type + \"/\" + index_list_file_name + \".txt\", \"w\", encoding='utf-8')\n",
    "            layer_index_file = open(index_layer_path + \"/\" + layer_type + \"/\" + index_list_file_name, \"w\", encoding='utf-8')\n",
    "            while query_output_line != \"\\n\":\n",
    "                #print(query_output_line)\n",
    "                query_output_line_list = query_output_line.replace(\"\\n\", \"\").split()\n",
    "                output_line_to_write = \" \".join(query_output_line_list[-3:]) + \"\\n\"\n",
    "                layer_index_file.write(output_line_to_write)\n",
    "                query_output_line = query_output_file.readline()\n",
    "            layer_index_file.close()\n",
    "            query_line = query_file.readline()\n",
    "            \n",
    "    query_file.close()\n",
    "    query_output_file.close()\n",
    "        \n",
    "    \n",
    "def split_test_query_output():\n",
    "    test_query_file_name = \"aol_testing.txt\"\n",
    "    #test_query_file_name = \"aol_testing_filtered.txt\"\n",
    "    test_query_file = open(test_query_file_name, \"r\", encoding='utf-8')\n",
    "    \n",
    "    test_query_output_file_name = \"./query output/aol_testing_output.txt\"\n",
    "    test_query_output_file = open(test_query_output_file_name, \"r\", encoding='utf-8')\n",
    "    \n",
    "    query_line = test_query_file.readline()\n",
    "    invalid_count = 0\n",
    "    while query_line:\n",
    "        # generate index list for this query\n",
    "        query_line = query_line.replace(\"\\n\", \"\")\n",
    "        colon_pos = query_line.index(\":\")\n",
    "        query_index = query_line[:colon_pos]\n",
    "        query_content = sorted(list(set(query_line[colon_pos + 1:].split())))\n",
    "        length = len(query_content)\n",
    "        split_output_file_name = query_index + \"_\" + \" \".join(query_content)\n",
    "        split_output_path = \"./Split Test Query Output\"\n",
    "        \n",
    "        query_output_line = test_query_output_file.readline()\n",
    "        \n",
    "        # if no document contain this term, just skip this query\n",
    "        if query_output_line == \"\\n\":\n",
    "            #no_output_query_idx.append(query_line)\n",
    "            \n",
    "            if length > 12:\n",
    "                print(\"Invalid Query:\", split_output_file_name)\n",
    "                query_line = test_query_file.readline()\n",
    "                invalid_count += 1\n",
    "                continue\n",
    "            split_output_file = open(split_output_path + \"/\" + split_output_file_name, \"w\", encoding='utf-8')\n",
    "            \n",
    "            split_output_file.close()\n",
    "            query_line = test_query_file.readline()\n",
    "\n",
    "        # there are some results for this query\n",
    "        else: \n",
    "            if len(split_output_file_name.split()) > 12:\n",
    "                print(\"Invalid Query:\", split_output_file_name)\n",
    "                query_line = test_query_file.readline()\n",
    "                invalid_count += 1\n",
    "                while query_output_line != \"\\n\":\n",
    "                    query_output_line = test_query_output_file.readline()\n",
    "                continue\n",
    "            split_output_file = open(split_output_path + \"/\" + split_output_file_name, \"w\", encoding='utf-8')\n",
    "            while query_output_line != \"\\n\":\n",
    "                query_output_line_list = query_output_line.replace(\"\\n\", \"\").split()\n",
    "                output_line_to_write = \" \".join(query_output_line_list[-3:]) + \"\\n\"\n",
    "                split_output_file.write(output_line_to_write)\n",
    "                query_output_line = test_query_output_file.readline()\n",
    "                \n",
    "            split_output_file.close()\n",
    "            query_line = test_query_file.readline()\n",
    "    \n",
    "    test_query_file.close()\n",
    "    test_query_output_file.close()\n",
    "    \n",
    "    print(\"Invalid Query:\", invalid_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fb954e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nstart_time = datetime.now()\\nlayer_type = \"duplet\"\\ncreate_1st_layer(layer_type)\\ntotal_running_time = datetime.now() - start_time\\nprint(\"Time to Create 1st Layer for \" + layer_type + \" :\", str(total_running_time.total_seconds()) + \"s\")\\nprint(no_output_query_idx)\\nprint(len(no_output_query_idx))\\n'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "start_time = datetime.now()\n",
    "layer_type = \"duplet\"\n",
    "create_1st_layer(layer_type)\n",
    "total_running_time = datetime.now() - start_time\n",
    "print(\"Time to Create 1st Layer for \" + layer_type + \" :\", str(total_running_time.total_seconds()) + \"s\")\n",
    "print(no_output_query_idx)\n",
    "print(len(no_output_query_idx))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0b425cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found\n",
      "Time to Create 1st Layer for complete_single : 128.327916s\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "#layer_type = \"single\"\n",
    "layer_type = \"complete_single\"\n",
    "create_1st_layer(layer_type)\n",
    "total_running_time = datetime.now() - start_time\n",
    "print(\"Time to Create 1st Layer for \" + layer_type + \" :\", str(total_running_time.total_seconds()) + \"s\")\n",
    "#print(no_output_query_idx)\n",
    "#print(len(no_output_query_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dc641a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to Create 1st Layer for duplet : 236.204164s\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "layer_type = \"duplet\"\n",
    "create_1st_layer(layer_type)\n",
    "total_running_time = datetime.now() - start_time\n",
    "print(\"Time to Create 1st Layer for \" + layer_type + \" :\", str(total_running_time.total_seconds()) + \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee1cb84",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "layer_type = \"triplet\"\n",
    "create_1st_layer(layer_type)\n",
    "total_running_time = datetime.now() - start_time\n",
    "print(\"Time to Create 1st Layer for \" + layer_type + \" :\", str(total_running_time.total_seconds()) + \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8da8f9",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "layer_type = \"quadruplet\"\n",
    "create_1st_layer(layer_type)\n",
    "total_running_time = datetime.now() - start_time\n",
    "print(\"Time to Create 1st Layer for \" + layer_type + \" :\", str(total_running_time.total_seconds()) + \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2367383",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "split_test_query_output()\n",
    "total_running_time = datetime.now() - start_time\n",
    "print(\"Time to Split Output of Test Queries:\", str(total_running_time.total_seconds()) + \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca2dfba",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}